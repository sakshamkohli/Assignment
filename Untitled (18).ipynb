{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac0c898b-b492-469c-923e-51a127d4c47a",
   "metadata": {},
   "source": [
    "Q1. Describe the decision tree classifier algorithm and how it works to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9467d706-62f2-4a6e-a31d-bf64b3dce090",
   "metadata": {},
   "source": [
    "Decision tree works on the basis of a number of yes/no decisions. It splits the data points based on a condition until leaf nodes are achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03d2041-32c7-4f34-a68f-dba51e3dc2bb",
   "metadata": {},
   "source": [
    "Q2. Provide a step-by-step explanation of the mathematical intuition behind decision tree classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b086dc-6d75-45be-afd7-3d78559273b5",
   "metadata": {},
   "source": [
    "Entropy: is a measure of randomness or uncertainty in a dataset. In the context of decision trees, entropy is used to determine the purity of a node.\n",
    "Information Gain: It is used to decide the splitting criterion in a decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa132f94-ac38-4ed9-a199-e0733d034588",
   "metadata": {},
   "source": [
    "Q3. Explain how a decision tree classifier can be used to solve a binary classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a9be26-9603-4350-82c9-dd10e70caf45",
   "metadata": {},
   "source": [
    "-The decision tree building process starts at the root node, where the algorithm calculates the Information Gain or Gini Impurity for each feature to determine the best splitting criterion.\n",
    "\n",
    "-The dataset is recursively split into subsets based on the chosen splitting criterion until a stopping criterion is met (e.g., maximum tree depth, minimum number of samples in a node).\n",
    "\n",
    "-During training, the decision tree learns the patterns and decision rules from the training data. It creates a hierarchy of if-else conditions based on feature values to classify examples into the appropriate class.\n",
    "\n",
    "-Once the decision tree is built, you can use it to make predictions for new, unseen examples. The tree is traversed from the root node down to a leaf node based on the feature values of the example.\n",
    "\n",
    "-At each node, the algorithm follows the branch that corresponds to the feature value of the example until it reaches a leaf node, where the predicted class is determined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed789342-a4a1-4235-bc13-295d36f789eb",
   "metadata": {},
   "source": [
    "Q4. Discuss the geometric intuition behind decision tree classification and how it can be used to make\n",
    "predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce3cc16-b6b4-4e7e-af2e-7c0140fda65d",
   "metadata": {},
   "source": [
    "Geometrically the decision tree devides the data points into sub segments based on a series of yes no questions. The leaf nodes thus obtained are the segregated required data points which are easily classifyble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45012d4f-5d87-42b4-a5de-fe303b9ae475",
   "metadata": {},
   "source": [
    "Q5. Define the confusion matrix and describe how it can be used to evaluate the performance of a\n",
    "classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f0edcd-71f2-4b15-a3fe-202dc4cd481c",
   "metadata": {},
   "source": [
    "Confusion matrocs is used to measure the quality of true and false classifications. It is used to represent true positives, false positives, true negitives and false negitives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11046167-7259-4b49-88c1-6ff259d317d3",
   "metadata": {},
   "source": [
    "Q6. Provide an example of a confusion matrix and explain how precision, recall, and F1 score can be\n",
    "calculated from it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc43a840-27b9-438c-8851-c4cc41280449",
   "metadata": {},
   "source": [
    "Actual/Predicted     Positive (P)     Negative (N)\n",
    "Positive (P)            TP                  FP\n",
    "Negative (N)            FN                  TN\n",
    "\n",
    "\n",
    "Precision is the measure of accuracy of true positives among all true positives and false positives\n",
    "Recall is the measure of true positives among all actual positive instances\n",
    "F1 score is harmonic mean of precision and recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2c5e17-7789-405f-9daf-1b68389a064d",
   "metadata": {},
   "source": [
    "Q7. Discuss the importance of choosing an appropriate evaluation metric for a classification problem and\n",
    "explain how this can be done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2d29ba-2335-4f79-864d-35abbecc6b34",
   "metadata": {},
   "source": [
    "Many different evaluation metrics serve different purposes. The appropriate evaluation metrics can be chosen basis of the busness problem, hadling class imbalences,evaluating tradeoffs between precision and recall and the needs of the business problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6430a840-0805-42f5-bf70-060474b11084",
   "metadata": {},
   "source": [
    "Q8. Provide an example of a classification problem where precision is the most important metric, and\n",
    "explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45b56e3-f94b-427f-9287-541782f17ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
